{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mongo db operation\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langdetect import detect, DetectorFactory\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import ast\n",
    "import re\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient(host='localhost', port=27017)\n",
    "#database name as frank\n",
    "db = client.frank\n",
    "#collection name as news\n",
    "db.tweets.drop()\n",
    "tweets = db.tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "donaldtrump = pd.read_csv('twitter/donaldtrump.csv')\n",
    "elonmusk = pd.read_csv('twitter/elonmusk.csv')\n",
    "gretathunberg = pd.read_csv('twitter/gretathunberg.csv')\n",
    "oprah = pd.read_csv('twitter/oprah.csv')\n",
    "rickygervais = pd.read_csv('twitter/rickygervais.csv')\n",
    "rosemcgowan = pd.read_csv('twitter/rosemcgowan.csv')\n",
    "sadqoutes = pd.read_csv('twitter/sadqoutes.csv')\n",
    "smilegenerator = pd.read_csv('twitter/smilegenerator.csv')\n",
    "snowden = pd.read_csv('twitter/snowden.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nonEnglish(dataset):\n",
    "    DetectorFactory.seed = 0\n",
    "    tweet_lines_english = []\n",
    "    test = dataset['text']\n",
    "    for i in test:\n",
    "    #detect pure url, NaN, empty strings result in excpetion\n",
    "        try:\n",
    "            if (detect(i) == 'en'):\n",
    "                tweet_lines_english.append(i)\n",
    "            else:\n",
    "                tweet_lines_english.append(\"none\")\n",
    "        except:\n",
    "            tweet_lines_english.append(\"none\")\n",
    "    #add a column to tweet matrix\n",
    "    dataset[\"englishText\"] = tweet_lines_english\n",
    "    indexNames = dataset[dataset['englishText'] == \"none\"].index\n",
    "    dataset.drop(indexNames, inplace = True)\n",
    "    dataset.drop(\"text\", axis=1, inplace=True)\n",
    "    dataset = dataset.reset_index(drop=True)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "donaldtrump = remove_nonEnglish(donaldtrump)\n",
    "elonmusk = remove_nonEnglish(elonmusk)\n",
    "gretathunberg = remove_nonEnglish(gretathunberg)\n",
    "oprah = remove_nonEnglish(oprah)\n",
    "rickygervais = remove_nonEnglish(rickygervais)\n",
    "rosemcgowan = remove_nonEnglish(rosemcgowan)\n",
    "sadqoutes = remove_nonEnglish(sadqoutes)\n",
    "smilegenerator = remove_nonEnglish(smilegenerator)\n",
    "snowden = remove_nonEnglish(snowden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter = [donaldtrump,elonmusk,gretathunberg,oprah,rickygervais,rosemcgowan,sadqoutes,smilegenerator,snowden]\n",
    "#twitter = [donaldtrump]\n",
    "#twitter_name = ['donaldtrump']\n",
    "twitter_name = ['donaldtrump','elonmusk','gretathunberg','oprah','rickygervais','rosemcgowan','sadqoutes','smilegenerator','snowden']\n",
    "topics = ['sports','others','scitech','videogames','politics','travel','food','entertainment','health','finance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "text = []\n",
    "users_emotion={}\n",
    "url = 'https://0ujrqdyqc6.execute-api.ap-southeast-2.amazonaws.com/test/mojiresource'\n",
    "url1 = 'https://0ujrqdyqc6.execute-api.ap-southeast-2.amazonaws.com/test/subjresource'\n",
    "for i in range(len(twitter)):\n",
    "    Anger = []\n",
    "    Joy = []\n",
    "    Sad = []\n",
    "    Fear = []\n",
    "    Disgust = []\n",
    "    Text = []\n",
    "    empath_result = []\n",
    "    subject_clf = []\n",
    "    for j in range(len(twitter[i])):\n",
    "        s = twitter[i]['englishText'][j]\n",
    "        try:\n",
    "            #s = re.sub('[^0-9a-zA-Z]+', ' ', s)\n",
    "            y = '{\"id\": \"123\", \"text\" : \"' + s + '\", \"userId\": \"123\" , \"timestamp\" :  \"2019/11/06\", \"applications\" : \"fb\"}'\n",
    "            r = requests.post(url, data=y)\n",
    "            data = r.json()\n",
    "            a = [key.split(',') for key in data.values()]\n",
    "            #print(a[0])\n",
    "            a = a[0][0:20]\n",
    "        except:\n",
    "            break\n",
    "        Anger.append(float(a[2].split(\":\",1)[1]) )\n",
    "        Joy.append(float(a[6].split(\":\",1)[1]) )\n",
    "        Sad.append(float(a[10].split(\":\",1)[1]) )\n",
    "        Fear.append(float(a[14].split(\":\",1)[1]) )\n",
    "        Disgust.append(float(a[18].split(\":\",1)[1]) )\n",
    "        Text.append(s)\n",
    "        x = '{\"msg\" : \"' + s + '\"}'\n",
    "        r1 = requests.post(url1, data=x)\n",
    "        data1 = r1.json()\n",
    "        empath_result.append(data1['body']['empath_result'])\n",
    "        subject_clf.append(data1['body']['subject_clf'])\n",
    "    tweet = []\n",
    "    for l in range(len(empath_result)):\n",
    "        strs = str(empath_result[l]).replace(\"[]\", \"\")\n",
    "        tweet.append(re.findall(r\"'(.*?)'\", strs, re.DOTALL))\n",
    "    users_emotion[i]=[Anger,Joy,Sad,Fear,Disgust,Text,tweet,subject_clf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in users_emotion.keys():\n",
    "    df = pd.DataFrame()\n",
    "    count = 0\n",
    "    v = []\n",
    "    while(count<len(users_emotion[i][0])):\n",
    "        v.append(twitter_name[i])\n",
    "        count+=1\n",
    "    df['Twitter'] = v\n",
    "    df['Anger'] = users_emotion[i][0]\n",
    "    df['Joy'] = users_emotion[i][1]\n",
    "    df['Sad'] = users_emotion[i][2]\n",
    "    df['Fear'] = users_emotion[i][3]\n",
    "    df['Disgust'] = users_emotion[i][4]\n",
    "    df['Text'] = users_emotion[i][5]\n",
    "    df['empath_result'] = users_emotion[i][6]\n",
    "    df['subject_clf'] = users_emotion[i][7]\n",
    "    li = []\n",
    "    for j in range(len(df)):\n",
    "        a = str(df['empath_result'][j]).replace(\"[]\", \" \")\n",
    "        li.append(a)\n",
    "    df['empath'] = li\n",
    "    del df['empath_result']\n",
    "    \n",
    "    for j in range(len(df)):\n",
    "        tweetsData = {}\n",
    "        tweetsData['UserName'] = df['Twitter'][j]\n",
    "        tweetsData['Anger'] = df['Anger'][j]\n",
    "        tweetsData['Joy'] = df['Joy'][j]\n",
    "        tweetsData['Sad'] = df['Sad'][j]\n",
    "        tweetsData['Fear'] = df['Fear'][j]\n",
    "        tweetsData['Disgust'] = df['Disgust'][j]\n",
    "        tweetsData['Text'] = df['Text'][j]\n",
    "        tweetsData['subject_clf'] = df['subject_clf'][j]\n",
    "        tweetsData['empath'] = df['empath'][j]\n",
    "        tweets.insert_one(tweetsData).inserted_id\n",
    "    #df.to_csv('output'+ str(i) +'.csv', index=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
